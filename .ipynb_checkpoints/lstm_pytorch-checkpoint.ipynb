{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_xx = spacy.load('xx_ent_wiki_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fenomen.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data = data.replace('\\n', ' ').replace('a', 'а').strip()\n",
    "sents = data.split('.')\n",
    "data = \" EOS \".join(sents) #[\"START \" + s for s in sents]\n",
    "data = re.sub(' +',' ', data) # just to handle this naughty spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Для нас дух имеет своей предпосылкой природу, он является ее истиной, и тем самым абсолютно первым в отношении ее EOS В этой истине природа исчезла, и дух обнаружился в ней как идея, достигшая своего для-себя-бытия, - как идея, объект которой, так же'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordlist(doc):\n",
    "    wl = []\n",
    "    for word in doc:\n",
    "        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "            wl.append(word.text.lower())\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spacy_xx(data)\n",
    "wl = create_wordlist(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['для',\n",
       " 'нас',\n",
       " 'дух',\n",
       " 'имеет',\n",
       " 'своей',\n",
       " 'предпосылкой',\n",
       " 'природу',\n",
       " ',',\n",
       " 'он',\n",
       " 'является',\n",
       " 'ее',\n",
       " 'истиной',\n",
       " ',',\n",
       " 'и',\n",
       " 'тем',\n",
       " 'самым',\n",
       " 'абсолютно',\n",
       " 'первым',\n",
       " 'в',\n",
       " 'отношении',\n",
       " 'ее',\n",
       " 'eos',\n",
       " 'в',\n",
       " 'этой',\n",
       " 'истине',\n",
       " 'природа',\n",
       " 'исчезла',\n",
       " ',',\n",
       " 'и',\n",
       " 'дух',\n",
       " 'обнаружился',\n",
       " 'в',\n",
       " 'ней',\n",
       " 'как',\n",
       " 'идея',\n",
       " ',',\n",
       " 'достигшая',\n",
       " 'своего',\n",
       " 'для-себя-бытия',\n",
       " ',',\n",
       " '-',\n",
       " 'как',\n",
       " 'идея',\n",
       " ',',\n",
       " 'объект',\n",
       " 'которой',\n",
       " ',',\n",
       " 'так',\n",
       " 'же',\n",
       " 'как',\n",
       " 'и',\n",
       " 'ее',\n",
       " 'субъект',\n",
       " ',',\n",
       " 'есть',\n",
       " 'понятие',\n",
       " 'eos',\n",
       " 'это',\n",
       " 'тождество',\n",
       " 'есть',\n",
       " 'абсолютная',\n",
       " 'отрицательность',\n",
       " ',',\n",
       " 'ибо',\n",
       " 'в',\n",
       " 'природе',\n",
       " 'понятие',\n",
       " 'обладает',\n",
       " 'своей',\n",
       " 'полной',\n",
       " 'внешней',\n",
       " 'объективностью',\n",
       " ',',\n",
       " 'однако',\n",
       " 'это',\n",
       " 'его',\n",
       " 'отчуждение',\n",
       " 'становится',\n",
       " 'тождественным',\n",
       " 'с',\n",
       " 'самим',\n",
       " 'собой',\n",
       " 'eos',\n",
       " 'тем',\n",
       " 'самым',\n",
       " 'оно',\n",
       " 'есть',\n",
       " 'это',\n",
       " 'тождество',\n",
       " 'только',\n",
       " 'как',\n",
       " 'возвращение',\n",
       " 'к',\n",
       " 'себе',\n",
       " 'из',\n",
       " 'природы',\n",
       " 'eos',\n",
       " 'развитие',\n",
       " 'духа',\n",
       " 'состоит',\n",
       " 'в',\n",
       " 'том',\n",
       " ',',\n",
       " 'что',\n",
       " 'он',\n",
       " 'существует',\n",
       " ':',\n",
       " '1',\n",
       " 'eos',\n",
       " 'в',\n",
       " 'форме',\n",
       " 'отношения',\n",
       " 'к',\n",
       " 'самому',\n",
       " 'себе',\n",
       " ';',\n",
       " 'что',\n",
       " 'в',\n",
       " 'его',\n",
       " 'пределах',\n",
       " 'идеальная',\n",
       " 'тотальность',\n",
       " 'идеи',\n",
       " ',',\n",
       " 'т',\n",
       " 'eos',\n",
       " 'е',\n",
       " 'eos',\n",
       " 'то',\n",
       " 'что',\n",
       " 'составляет',\n",
       " 'его',\n",
       " 'понятие',\n",
       " ',',\n",
       " 'становится',\n",
       " 'таковой',\n",
       " 'для',\n",
       " 'него',\n",
       " ',',\n",
       " 'и',\n",
       " 'его',\n",
       " 'бытие',\n",
       " 'состоит',\n",
       " 'в',\n",
       " 'том',\n",
       " ',',\n",
       " 'чтобы',\n",
       " 'быть',\n",
       " 'у',\n",
       " 'себя',\n",
       " ',',\n",
       " 'т',\n",
       " 'eos',\n",
       " 'е',\n",
       " 'eos',\n",
       " 'быть',\n",
       " 'свободным',\n",
       " ',',\n",
       " '-',\n",
       " 'это',\n",
       " 'субъективный',\n",
       " 'дух',\n",
       " 'eos',\n",
       " '2',\n",
       " 'eos',\n",
       " 'в',\n",
       " 'форме',\n",
       " 'реальности',\n",
       " ',',\n",
       " 'как',\n",
       " 'подлежащий',\n",
       " 'порождению',\n",
       " 'духом',\n",
       " 'и',\n",
       " 'порожденный',\n",
       " 'им',\n",
       " 'мир',\n",
       " ',',\n",
       " 'в',\n",
       " 'котором',\n",
       " 'свобода',\n",
       " 'имеет',\n",
       " 'место',\n",
       " 'как',\n",
       " 'наличная',\n",
       " 'необходимость',\n",
       " ',',\n",
       " '-',\n",
       " 'это',\n",
       " 'объективный',\n",
       " 'дух',\n",
       " 'eos',\n",
       " '3',\n",
       " 'eos',\n",
       " 'как',\n",
       " 'в',\n",
       " 'себе',\n",
       " 'и',\n",
       " 'для',\n",
       " 'себя',\n",
       " 'сущее',\n",
       " 'и',\n",
       " 'вечно',\n",
       " 'себя',\n",
       " 'порождающее',\n",
       " 'единство',\n",
       " 'объективности',\n",
       " 'духа',\n",
       " 'и',\n",
       " 'его',\n",
       " 'идеальности',\n",
       " ',',\n",
       " 'или',\n",
       " 'его',\n",
       " 'понятия',\n",
       " ',',\n",
       " 'дух',\n",
       " 'в',\n",
       " 'его',\n",
       " 'абсолютной',\n",
       " 'истине',\n",
       " '-',\n",
       " 'это',\n",
       " 'абсолютный',\n",
       " 'дух',\n",
       " 'eos',\n",
       " 'дух',\n",
       " 'существенно',\n",
       " 'есть',\n",
       " 'только',\n",
       " 'то',\n",
       " ',',\n",
       " 'что',\n",
       " 'он',\n",
       " 'знает',\n",
       " 'о',\n",
       " 'самом',\n",
       " 'себе',\n",
       " 'eos',\n",
       " 'первоначально',\n",
       " 'он',\n",
       " 'есть',\n",
       " 'дух',\n",
       " 'только',\n",
       " 'в',\n",
       " 'себе',\n",
       " ';',\n",
       " 'его',\n",
       " 'становление',\n",
       " 'для',\n",
       " 'себя',\n",
       " 'составляет',\n",
       " 'его',\n",
       " 'осуществление',\n",
       " 'eos',\n",
       " 'но',\n",
       " 'духом',\n",
       " 'для',\n",
       " 'себя',\n",
       " 'он',\n",
       " 'становится',\n",
       " 'только',\n",
       " 'через',\n",
       " 'то',\n",
       " ',',\n",
       " 'что',\n",
       " 'он',\n",
       " 'себя',\n",
       " 'обособляет',\n",
       " ',',\n",
       " 'определяет',\n",
       " 'себя',\n",
       " ',',\n",
       " 'или',\n",
       " 'делает',\n",
       " 'себя',\n",
       " 'своим',\n",
       " 'предположением',\n",
       " ',',\n",
       " 'своим',\n",
       " 'другим',\n",
       " ',',\n",
       " 'прежде',\n",
       " 'всего',\n",
       " 'относя',\n",
       " 'себя',\n",
       " 'к',\n",
       " 'этому',\n",
       " 'другому',\n",
       " 'как',\n",
       " 'к',\n",
       " 'своей',\n",
       " 'непосредственности',\n",
       " ',',\n",
       " 'но',\n",
       " 'в',\n",
       " 'то',\n",
       " 'же',\n",
       " 'время',\n",
       " 'и',\n",
       " 'снимая',\n",
       " 'его',\n",
       " 'как',\n",
       " 'другое',\n",
       " 'eos',\n",
       " 'до',\n",
       " 'тех',\n",
       " 'пор',\n",
       " ',',\n",
       " 'пока',\n",
       " 'дух',\n",
       " 'находится',\n",
       " 'в',\n",
       " 'отношении',\n",
       " 'к',\n",
       " 'самому',\n",
       " 'себе',\n",
       " 'как',\n",
       " 'некоему',\n",
       " 'другому',\n",
       " ',',\n",
       " 'он',\n",
       " 'является',\n",
       " 'только',\n",
       " 'субъективным',\n",
       " 'духом',\n",
       " ',',\n",
       " '-',\n",
       " 'духом',\n",
       " ',',\n",
       " 'берущим',\n",
       " 'свое',\n",
       " 'начало',\n",
       " 'из',\n",
       " 'природы',\n",
       " ',',\n",
       " 'и',\n",
       " 'первоначально',\n",
       " 'только',\n",
       " 'природным',\n",
       " 'духом',\n",
       " 'eos',\n",
       " 'но',\n",
       " 'вся',\n",
       " 'деятельность',\n",
       " 'субъективного',\n",
       " 'духа',\n",
       " 'сводится',\n",
       " 'к',\n",
       " 'тому',\n",
       " ',',\n",
       " 'чтобы',\n",
       " 'постигнуть',\n",
       " 'себя',\n",
       " 'в',\n",
       " 'себе',\n",
       " 'самом',\n",
       " ',',\n",
       " 'раскрыть',\n",
       " 'себя',\n",
       " 'как',\n",
       " 'идеальность',\n",
       " 'своей',\n",
       " 'непосредственной',\n",
       " 'реальности',\n",
       " 'eos',\n",
       " 'дух',\n",
       " ',',\n",
       " 'развивающийся',\n",
       " 'в',\n",
       " 'своей',\n",
       " 'идеальности',\n",
       " ',',\n",
       " 'есть',\n",
       " 'дух',\n",
       " 'познающий',\n",
       " 'eos',\n",
       " 'но',\n",
       " 'познание',\n",
       " 'не',\n",
       " 'понимается',\n",
       " 'здесь',\n",
       " 'просто',\n",
       " 'как',\n",
       " 'определенность',\n",
       " 'идеи',\n",
       " ',',\n",
       " 'как',\n",
       " 'логическая',\n",
       " 'идея',\n",
       " ',',\n",
       " 'но',\n",
       " 'понимается',\n",
       " 'так',\n",
       " ',',\n",
       " 'как',\n",
       " 'конкретный',\n",
       " 'дух',\n",
       " 'определяет',\n",
       " 'себя',\n",
       " 'к',\n",
       " 'этому',\n",
       " 'познанию',\n",
       " 'eos',\n",
       " 'субъективный',\n",
       " 'дух',\n",
       " 'есть',\n",
       " ':',\n",
       " 'дух',\n",
       " 'в',\n",
       " 'себе',\n",
       " ',',\n",
       " 'или',\n",
       " 'непосредственный',\n",
       " ';',\n",
       " 'в',\n",
       " 'этом',\n",
       " 'смысле',\n",
       " 'он',\n",
       " 'есть',\n",
       " 'душа',\n",
       " ',',\n",
       " 'или',\n",
       " 'природный',\n",
       " 'дух',\n",
       " ';',\n",
       " '-',\n",
       " 'предмет',\n",
       " 'антропологии',\n",
       " ';',\n",
       " 'дух',\n",
       " 'для',\n",
       " 'себя',\n",
       " ',',\n",
       " 'или',\n",
       " 'опосредственный',\n",
       " ',',\n",
       " 'понятый',\n",
       " 'еще',\n",
       " 'как',\n",
       " 'тождественная',\n",
       " 'рефлексия',\n",
       " 'в',\n",
       " 'себе',\n",
       " 'и',\n",
       " 'по',\n",
       " 'отношению',\n",
       " 'к',\n",
       " 'другому',\n",
       " ';',\n",
       " 'дух',\n",
       " 'в',\n",
       " 'отношении',\n",
       " ',',\n",
       " 'или',\n",
       " 'обособлении',\n",
       " ';',\n",
       " 'сознание',\n",
       " '-',\n",
       " 'предмет',\n",
       " 'феноменологии',\n",
       " 'духа',\n",
       " 'eos',\n",
       " 'себя',\n",
       " 'в',\n",
       " 'себе',\n",
       " 'определяющий',\n",
       " 'дух',\n",
       " 'как',\n",
       " 'субъект',\n",
       " 'для',\n",
       " 'себя',\n",
       " ',',\n",
       " '-',\n",
       " 'предмет',\n",
       " 'психологии',\n",
       " 'eos',\n",
       " 'в',\n",
       " 'душе',\n",
       " 'пробуждается',\n",
       " 'сознание',\n",
       " ';',\n",
       " 'сознание',\n",
       " 'полагает',\n",
       " 'себя',\n",
       " 'как',\n",
       " 'разум',\n",
       " ',',\n",
       " 'который',\n",
       " 'непосредственно',\n",
       " 'пробудился',\n",
       " ',',\n",
       " 'как',\n",
       " 'себя',\n",
       " 'знающий',\n",
       " 'разум',\n",
       " ',',\n",
       " 'освобождающий',\n",
       " 'себя',\n",
       " 'посредством',\n",
       " 'своей',\n",
       " 'деятельности',\n",
       " 'до',\n",
       " 'степени',\n",
       " 'объективности',\n",
       " ',',\n",
       " 'до',\n",
       " 'сознания',\n",
       " 'своего',\n",
       " 'понятия',\n",
       " 'eos',\n",
       " 'сознание',\n",
       " 'eos',\n",
       " 'сознание',\n",
       " 'составляет',\n",
       " 'ступень',\n",
       " 'рефлексии',\n",
       " ',',\n",
       " 'или',\n",
       " 'отношения',\n",
       " 'духа',\n",
       " ',',\n",
       " 'его',\n",
       " 'развития',\n",
       " 'как',\n",
       " 'явления',\n",
       " 'eos',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'есть',\n",
       " 'бесконечное',\n",
       " 'отношение',\n",
       " 'духа',\n",
       " 'к',\n",
       " 'себе',\n",
       " ',',\n",
       " 'но',\n",
       " 'как',\n",
       " 'субъективное',\n",
       " ',',\n",
       " 'как',\n",
       " 'достоверность',\n",
       " 'самого',\n",
       " 'себя',\n",
       " ';',\n",
       " 'непосредственное',\n",
       " 'тождество',\n",
       " 'природной',\n",
       " 'души',\n",
       " 'поднято',\n",
       " 'до',\n",
       " 'этого',\n",
       " 'чисто',\n",
       " 'идеального',\n",
       " 'тождества',\n",
       " 'ее',\n",
       " 'с',\n",
       " 'собой',\n",
       " ';',\n",
       " 'содержание',\n",
       " 'этого',\n",
       " 'тождества',\n",
       " 'является',\n",
       " 'предметом',\n",
       " 'этой',\n",
       " 'для-себя-сущей',\n",
       " 'рефлексии',\n",
       " 'eos',\n",
       " 'чистая',\n",
       " 'абстрактная',\n",
       " 'свобода',\n",
       " 'духа',\n",
       " 'для',\n",
       " 'себя',\n",
       " 'отпускает',\n",
       " 'из',\n",
       " 'себя',\n",
       " 'свою',\n",
       " 'определенность',\n",
       " ',',\n",
       " 'природную',\n",
       " 'жизнь',\n",
       " 'души',\n",
       " ',',\n",
       " 'которая',\n",
       " 'также',\n",
       " 'свободна',\n",
       " ',',\n",
       " 'как',\n",
       " 'самостоятельный',\n",
       " 'объект',\n",
       " ';',\n",
       " 'об',\n",
       " 'этом-то',\n",
       " 'объекте',\n",
       " ',',\n",
       " 'как',\n",
       " 'для',\n",
       " 'него',\n",
       " 'внешнем',\n",
       " ',',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'и',\n",
       " 'получает',\n",
       " 'прежде',\n",
       " 'всего',\n",
       " 'знание',\n",
       " 'и',\n",
       " ',',\n",
       " 'таким',\n",
       " 'образом',\n",
       " ',',\n",
       " 'является',\n",
       " 'сознанием',\n",
       " 'eos',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'как',\n",
       " 'эта',\n",
       " 'абсолютная',\n",
       " 'отрицательность',\n",
       " ',',\n",
       " 'есть',\n",
       " 'в',\n",
       " 'себе',\n",
       " 'тождество',\n",
       " 'в',\n",
       " 'инобытии',\n",
       " ';',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'есть',\n",
       " 'оно',\n",
       " 'само',\n",
       " 'и',\n",
       " 'выходит',\n",
       " 'за',\n",
       " 'пределы',\n",
       " 'объекта',\n",
       " 'как',\n",
       " 'чего-то',\n",
       " 'снятого',\n",
       " 'в',\n",
       " 'себе',\n",
       " ';',\n",
       " 'оно',\n",
       " 'есть',\n",
       " 'и',\n",
       " 'одна',\n",
       " 'сторона',\n",
       " 'отношения',\n",
       " 'и',\n",
       " 'все',\n",
       " 'это',\n",
       " 'отношение',\n",
       " 'в',\n",
       " 'целом',\n",
       " ',',\n",
       " '-',\n",
       " 'свет',\n",
       " ',',\n",
       " 'обнаруживающий',\n",
       " 'себя',\n",
       " ',',\n",
       " 'и',\n",
       " 'другое',\n",
       " 'eos',\n",
       " 'прибавление',\n",
       " 'eos',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'должно',\n",
       " 'быть',\n",
       " 'понято',\n",
       " 'как',\n",
       " 'индивидуально',\n",
       " 'определенное',\n",
       " ',',\n",
       " 'в',\n",
       " 'своей',\n",
       " 'определенности',\n",
       " 'и',\n",
       " 'в',\n",
       " 'своем',\n",
       " 'различии',\n",
       " 'только',\n",
       " 'к',\n",
       " 'себе',\n",
       " 'самому',\n",
       " 'относящееся',\n",
       " 'всеобщее',\n",
       " 'eos',\n",
       " 'в',\n",
       " 'этом',\n",
       " 'содержится',\n",
       " 'уже',\n",
       " 'что',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'есть',\n",
       " 'непосредственно',\n",
       " 'отрицательное',\n",
       " 'отношение',\n",
       " 'к',\n",
       " 'самому',\n",
       " 'себе',\n",
       " ',',\n",
       " '-',\n",
       " 'следовательно',\n",
       " ',',\n",
       " 'непосредственная',\n",
       " 'противоположность',\n",
       " 'его',\n",
       " 'всеобщности',\n",
       " ',',\n",
       " 'абстрагированной',\n",
       " 'от',\n",
       " 'всякой',\n",
       " 'определенности',\n",
       " ',',\n",
       " 'и',\n",
       " 'в',\n",
       " 'такой',\n",
       " 'же',\n",
       " 'мере',\n",
       " 'абстрактная',\n",
       " ',',\n",
       " 'простая',\n",
       " 'единичность',\n",
       " 'eos',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'само',\n",
       " 'есть',\n",
       " 'это',\n",
       " 'различение',\n",
       " 'себя',\n",
       " 'от',\n",
       " 'самого',\n",
       " 'себя',\n",
       " ';',\n",
       " 'ибо',\n",
       " ',',\n",
       " 'как',\n",
       " 'сама',\n",
       " 'к',\n",
       " 'себе',\n",
       " 'относящаяся',\n",
       " ',',\n",
       " 'его',\n",
       " 'исключающая',\n",
       " 'единичность',\n",
       " ',',\n",
       " 'она',\n",
       " 'исключает',\n",
       " 'из',\n",
       " 'себя',\n",
       " 'самой',\n",
       " ',',\n",
       " 'то',\n",
       " 'есть',\n",
       " 'из',\n",
       " 'единичности',\n",
       " ',',\n",
       " 'и',\n",
       " 'благодаря',\n",
       " 'этому',\n",
       " 'полагает',\n",
       " 'себя',\n",
       " 'как',\n",
       " 'некоторую',\n",
       " 'с',\n",
       " 'ней',\n",
       " 'непосредственно',\n",
       " 'сомкнутую',\n",
       " 'противоположность',\n",
       " 'себя',\n",
       " 'самой',\n",
       " ',',\n",
       " 'как',\n",
       " 'всеобщность',\n",
       " 'eos',\n",
       " 'но',\n",
       " 'существенное',\n",
       " 'для',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'определение',\n",
       " 'абстрактно',\n",
       " 'eos',\n",
       " 'я',\n",
       " 'и',\n",
       " 'мое',\n",
       " 'бытие',\n",
       " 'неразрывно',\n",
       " 'связаны',\n",
       " 'между',\n",
       " 'собой',\n",
       " ';',\n",
       " 'различие',\n",
       " 'моего',\n",
       " 'бытия',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'есть',\n",
       " 'различие',\n",
       " ',',\n",
       " 'которое',\n",
       " 'не',\n",
       " 'есть',\n",
       " 'различие',\n",
       " 'eos',\n",
       " 'правда',\n",
       " ',',\n",
       " 'с',\n",
       " 'одной',\n",
       " 'стороны',\n",
       " ',',\n",
       " 'бытие',\n",
       " 'как',\n",
       " 'нечто',\n",
       " 'абсолютно',\n",
       " 'непосредственное',\n",
       " ',',\n",
       " 'неопределенное',\n",
       " ',',\n",
       " 'неразличное',\n",
       " 'должно',\n",
       " 'быть',\n",
       " 'отличаемо',\n",
       " 'от',\n",
       " 'мышления',\n",
       " ',',\n",
       " 'отличающего',\n",
       " 'себя',\n",
       " 'от',\n",
       " 'самого',\n",
       " 'себя',\n",
       " ',',\n",
       " 'и',\n",
       " 'через',\n",
       " 'снятие',\n",
       " 'этого',\n",
       " 'различия',\n",
       " 'себя',\n",
       " 'с',\n",
       " 'самим',\n",
       " 'собой',\n",
       " 'опосредствующего',\n",
       " 'мышления',\n",
       " ',',\n",
       " '-',\n",
       " 'от',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " ';',\n",
       " 'тем',\n",
       " 'не',\n",
       " 'менее',\n",
       " ',',\n",
       " 'с',\n",
       " 'другой',\n",
       " 'стороны',\n",
       " ',',\n",
       " 'бытие',\n",
       " 'тождественно',\n",
       " 'с',\n",
       " 'мышлением',\n",
       " ',',\n",
       " 'ибо',\n",
       " 'это',\n",
       " 'последнее',\n",
       " 'от',\n",
       " 'всякого',\n",
       " 'опосредствования',\n",
       " 'возвращается',\n",
       " 'к',\n",
       " 'непосредственности',\n",
       " ',',\n",
       " 'от',\n",
       " 'всего',\n",
       " 'своего',\n",
       " 'саморазличия',\n",
       " '-',\n",
       " 'к',\n",
       " 'ничем',\n",
       " 'не',\n",
       " 'ограниченному',\n",
       " 'единству',\n",
       " 'с',\n",
       " 'самим',\n",
       " 'собой',\n",
       " 'eos',\n",
       " 'поэтому',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " 'есть',\n",
       " 'бытие',\n",
       " 'или',\n",
       " 'содержит',\n",
       " 'последнее',\n",
       " 'как',\n",
       " 'момент',\n",
       " 'в',\n",
       " 'самом',\n",
       " 'себе',\n",
       " 'eos',\n",
       " 'поскольку',\n",
       " 'это',\n",
       " 'бытие',\n",
       " 'я',\n",
       " 'полагаю',\n",
       " 'как',\n",
       " 'нечто',\n",
       " 'другое',\n",
       " 'по',\n",
       " 'отношению',\n",
       " 'ко',\n",
       " 'мне',\n",
       " 'и',\n",
       " 'в',\n",
       " 'то',\n",
       " 'как',\n",
       " 'нечто',\n",
       " 'другое',\n",
       " 'по',\n",
       " 'отношению',\n",
       " 'ко',\n",
       " 'мне',\n",
       " 'и',\n",
       " 'в',\n",
       " 'то',\n",
       " 'же',\n",
       " 'время',\n",
       " 'тождественное',\n",
       " 'со',\n",
       " 'мной',\n",
       " ',',\n",
       " 'постольку',\n",
       " 'я',\n",
       " 'есть',\n",
       " 'знание',\n",
       " 'и',\n",
       " 'обладаю',\n",
       " 'абсолютной',\n",
       " 'достоверностью',\n",
       " 'моего',\n",
       " 'бытия',\n",
       " 'eos',\n",
       " 'эта',\n",
       " 'достоверность',\n",
       " 'не',\n",
       " 'должна',\n",
       " 'быть',\n",
       " 'рассматриваема',\n",
       " ',',\n",
       " 'как',\n",
       " 'это',\n",
       " 'бывает',\n",
       " 'при',\n",
       " 'простом',\n",
       " 'представлении',\n",
       " ',',\n",
       " 'как',\n",
       " 'некоторый',\n",
       " 'род',\n",
       " 'свойства',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " ',',\n",
       " 'некоторое',\n",
       " 'определение',\n",
       " 'его',\n",
       " 'природы',\n",
       " ',',\n",
       " 'но',\n",
       " 'ее',\n",
       " 'следует',\n",
       " 'понимать',\n",
       " 'как',\n",
       " 'природу',\n",
       " 'самого',\n",
       " '\"',\n",
       " 'я',\n",
       " '\"',\n",
       " ',',\n",
       " 'и',\n",
       " 'в',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  1500\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "word_counts = collections.Counter(wl)\n",
    "\n",
    "N_most_common = 1500\n",
    "wc_most_common = word_counts.most_common(n=N_most_common)\n",
    "\n",
    "# Mapping from index to word : that's the vocabulary\n",
    "vocabulary_inv = [\"unknown\"] + [x[0] for x in wc_most_common]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in wc_most_common]\n",
    "\n",
    "#size of the vocabulary\n",
    "vocab_size = len(words)\n",
    "assert vocab_size == N_most_common #however I also have \"unknown\" token\n",
    "print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to avoid the situation when the network will try to predict a million-size vector of probabilities at each step, I just have cut the set of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "(\n",
      ")\n",
      ",\n",
      "-\n",
      "--\n",
      "1\n",
      "2\n",
      "3\n",
      ":\n",
      ";\n",
      "=\n",
      "_\n",
      "eos\n",
      "unknown\n"
     ]
    }
   ],
   "source": [
    "# this is just there were some 'a' (from English) characters; but they are not the same as from Cyrrilic glyph set\n",
    "for w in vocabulary_inv:\n",
    "    try:\n",
    "        w.encode('ascii')\n",
    "    except UnicodeEncodeError: \n",
    "        pass\n",
    "    else:\n",
    "        print(w)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '--',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '_',\n",
       " 'eos',\n",
       " 'unknown',\n",
       " 'а',\n",
       " 'абсолютная',\n",
       " 'абсолютно',\n",
       " 'абсолютное',\n",
       " 'абсолютной',\n",
       " 'абсолютный',\n",
       " 'абстрагированной',\n",
       " 'абстрактная',\n",
       " 'абстрактно',\n",
       " 'абстрактного',\n",
       " 'абстрактное',\n",
       " 'абстрактной',\n",
       " 'абстрактном',\n",
       " 'абстрактному',\n",
       " 'абстрактным',\n",
       " 'антропологии',\n",
       " 'антропологического',\n",
       " 'антропологичной',\n",
       " 'аперцепций',\n",
       " 'бедное',\n",
       " 'без',\n",
       " 'безусловно',\n",
       " 'берущим',\n",
       " 'бесконечного',\n",
       " 'бесконечное',\n",
       " 'бесконечному',\n",
       " 'бесконечность',\n",
       " 'бессилия',\n",
       " 'бессильная',\n",
       " 'бессодержательное',\n",
       " 'бессознательное',\n",
       " 'благодаря',\n",
       " 'ближайшая',\n",
       " 'ближайшей',\n",
       " 'ближайшим',\n",
       " 'бога',\n",
       " 'богатое',\n",
       " 'богатым',\n",
       " 'боге',\n",
       " 'божественного',\n",
       " 'более',\n",
       " 'болезненные',\n",
       " 'больше',\n",
       " 'большего',\n",
       " 'большей',\n",
       " 'борьба',\n",
       " 'борьбой',\n",
       " 'борьбу',\n",
       " 'борьбы',\n",
       " 'борющихся',\n",
       " 'брать',\n",
       " 'будто',\n",
       " 'будучи',\n",
       " 'будь',\n",
       " 'бы',\n",
       " 'бывает',\n",
       " 'был',\n",
       " 'была',\n",
       " 'были',\n",
       " 'было',\n",
       " 'бытие',\n",
       " 'бытии',\n",
       " 'бытию',\n",
       " 'бытия',\n",
       " 'быть',\n",
       " 'в',\n",
       " 'в-себе-и-для-себя',\n",
       " 'в-себе-и-для-себя-сущая',\n",
       " 'в-себе-и-для-себя-сущей',\n",
       " 'в-себе-сущее',\n",
       " 'в§414',\n",
       " 'в§415',\n",
       " 'в§416',\n",
       " 'в§417',\n",
       " 'в§418',\n",
       " 'в§419',\n",
       " 'в§420',\n",
       " 'важничания',\n",
       " 'ведет',\n",
       " 'верящим',\n",
       " 'вечно',\n",
       " 'вечному',\n",
       " 'вещ-в-себе',\n",
       " 'вещами',\n",
       " 'вещей',\n",
       " 'вещи',\n",
       " 'вещь',\n",
       " 'вещью-в-себе',\n",
       " 'взаимно',\n",
       " 'взаимном',\n",
       " 'вид',\n",
       " 'виде',\n",
       " 'видеть',\n",
       " 'видимость',\n",
       " 'вкус',\n",
       " 'вкуса',\n",
       " 'власти',\n",
       " 'влечение',\n",
       " 'влечения',\n",
       " 'вместе',\n",
       " 'вместо',\n",
       " 'вне',\n",
       " 'вне-себя-бытие',\n",
       " 'внеположности',\n",
       " 'внешне',\n",
       " 'внешнего',\n",
       " 'внешнее',\n",
       " 'внешней',\n",
       " 'внешнем',\n",
       " 'внешнему',\n",
       " 'внешний',\n",
       " 'внешним',\n",
       " 'внешними',\n",
       " 'внешности',\n",
       " 'внешность',\n",
       " 'внутренне',\n",
       " 'внутреннего',\n",
       " 'внутреннее',\n",
       " 'внутренней',\n",
       " 'внутреннем',\n",
       " 'внутреннему',\n",
       " 'внутренний',\n",
       " 'внутренним',\n",
       " 'внутреннюю',\n",
       " 'внутри',\n",
       " 'во',\n",
       " 'во-вторых',\n",
       " 'во-первых',\n",
       " 'вожделение',\n",
       " 'вожделением',\n",
       " 'вожделению',\n",
       " 'вожделения',\n",
       " 'возводимых',\n",
       " 'возвращается',\n",
       " 'возвращение',\n",
       " 'возвысившиеся',\n",
       " 'возвысились',\n",
       " 'возвышается',\n",
       " 'возвышения',\n",
       " 'воззрениями',\n",
       " 'возможность',\n",
       " 'возникает',\n",
       " 'возникнуть',\n",
       " 'воле',\n",
       " 'воли',\n",
       " 'волю',\n",
       " 'воля',\n",
       " 'вообще',\n",
       " 'вопреки',\n",
       " 'вопросе',\n",
       " 'воспринимающего',\n",
       " 'воспринимающее',\n",
       " 'восприятие',\n",
       " 'восприятия',\n",
       " 'восприять',\n",
       " 'вот',\n",
       " 'впадая',\n",
       " 'вперед',\n",
       " 'времени',\n",
       " 'временная',\n",
       " 'время',\n",
       " 'все',\n",
       " 'все-таки',\n",
       " 'всегда',\n",
       " 'всего',\n",
       " 'всем',\n",
       " 'всеобщая',\n",
       " 'всеобщего',\n",
       " 'всеобщее',\n",
       " 'всеобщей',\n",
       " 'всеобщему',\n",
       " 'всеобщий',\n",
       " 'всеобщностей',\n",
       " 'всеобщности',\n",
       " 'всеобщность',\n",
       " 'всеобщностью',\n",
       " 'всех',\n",
       " 'вследствие',\n",
       " 'вступает',\n",
       " 'вся',\n",
       " 'всякого',\n",
       " 'всякое',\n",
       " 'всякой',\n",
       " 'второй',\n",
       " 'выдающего',\n",
       " 'выражение',\n",
       " 'высказать',\n",
       " 'выступает',\n",
       " 'выступающий',\n",
       " 'высшее',\n",
       " 'вытекает',\n",
       " 'выходит',\n",
       " 'выходящее',\n",
       " 'выше',\n",
       " 'вышедшее',\n",
       " 'выясняется',\n",
       " 'где',\n",
       " 'говоря',\n",
       " 'голой',\n",
       " 'господин',\n",
       " 'господина',\n",
       " 'господином',\n",
       " 'господства',\n",
       " 'государств',\n",
       " 'государства',\n",
       " 'государстве',\n",
       " 'государство',\n",
       " 'грубости',\n",
       " 'д',\n",
       " 'дает',\n",
       " 'далее',\n",
       " 'дальнейшее',\n",
       " 'дальше',\n",
       " 'данного',\n",
       " 'данном',\n",
       " 'данные',\n",
       " 'данный',\n",
       " 'данным',\n",
       " 'данными',\n",
       " 'движение',\n",
       " 'действенную',\n",
       " 'действительно',\n",
       " 'действительного',\n",
       " 'действительное',\n",
       " 'действительности',\n",
       " 'действующей',\n",
       " 'делает',\n",
       " 'деле',\n",
       " 'дело',\n",
       " 'держится',\n",
       " 'детском',\n",
       " 'деятельности',\n",
       " 'деятельность',\n",
       " 'диалектическое',\n",
       " 'диалектично',\n",
       " 'для',\n",
       " 'для-себя-бытием',\n",
       " 'для-себя-бытия',\n",
       " 'для-себя-самого-себя-внешнем',\n",
       " 'для-себя-сущей',\n",
       " 'до',\n",
       " 'доказательства',\n",
       " 'доказательство',\n",
       " 'доказать',\n",
       " 'должен',\n",
       " 'долженствующим',\n",
       " 'должна',\n",
       " 'должно',\n",
       " 'должны',\n",
       " 'допущена',\n",
       " 'достаточно',\n",
       " 'достаточной',\n",
       " 'достаточностью',\n",
       " 'достигает',\n",
       " 'достигается',\n",
       " 'достигающее',\n",
       " 'достигшая',\n",
       " 'достижения',\n",
       " 'достоверное',\n",
       " 'достоверностей',\n",
       " 'достоверности',\n",
       " 'достоверность',\n",
       " 'достоверностью',\n",
       " 'достоверным',\n",
       " 'доступности',\n",
       " 'доходит',\n",
       " 'дошли',\n",
       " 'друг',\n",
       " 'друга',\n",
       " 'друге',\n",
       " 'другим',\n",
       " 'другими',\n",
       " 'других',\n",
       " 'другого',\n",
       " 'другое',\n",
       " 'другой',\n",
       " 'другом',\n",
       " 'другому',\n",
       " 'другу',\n",
       " 'дурным',\n",
       " 'дух',\n",
       " 'духа',\n",
       " 'духовного',\n",
       " 'духом',\n",
       " 'духу',\n",
       " 'душа',\n",
       " 'душе',\n",
       " 'души',\n",
       " 'е',\n",
       " 'его',\n",
       " 'единичного',\n",
       " 'единичное',\n",
       " 'единичной',\n",
       " 'единичном',\n",
       " 'единичному',\n",
       " 'единичности',\n",
       " 'единичность',\n",
       " 'единичные',\n",
       " 'единичным',\n",
       " 'единичными',\n",
       " 'единичных',\n",
       " 'единства',\n",
       " 'единстве',\n",
       " 'единственно',\n",
       " 'единство',\n",
       " 'единству',\n",
       " 'ее',\n",
       " 'ей',\n",
       " 'ему',\n",
       " 'если',\n",
       " 'естественном',\n",
       " 'есть',\n",
       " 'еще',\n",
       " 'же',\n",
       " 'живого',\n",
       " 'живое',\n",
       " 'живом',\n",
       " 'жизни',\n",
       " 'жизнь',\n",
       " 'жизнью',\n",
       " 'за',\n",
       " 'зависимое',\n",
       " 'загорается',\n",
       " 'заключается',\n",
       " 'закон',\n",
       " 'закона',\n",
       " 'закону',\n",
       " 'законы',\n",
       " 'заложена',\n",
       " 'заметить',\n",
       " 'запах',\n",
       " 'заслуживает',\n",
       " 'заставляет',\n",
       " 'затруднением',\n",
       " 'звено',\n",
       " 'здесь',\n",
       " 'знаем',\n",
       " 'знает',\n",
       " 'знание',\n",
       " 'знанием',\n",
       " 'знания',\n",
       " 'значение',\n",
       " 'знаю',\n",
       " 'знающий',\n",
       " 'зрения',\n",
       " 'и',\n",
       " 'ибо',\n",
       " 'идеальная',\n",
       " 'идеально',\n",
       " 'идеального',\n",
       " 'идеальности',\n",
       " 'идеальность',\n",
       " 'идее',\n",
       " 'идеи',\n",
       " 'идет',\n",
       " 'идея',\n",
       " 'идти',\n",
       " 'из',\n",
       " 'известно',\n",
       " 'изменение',\n",
       " 'изменением',\n",
       " 'изменения',\n",
       " 'изменяется',\n",
       " 'или',\n",
       " 'им',\n",
       " 'имеем',\n",
       " 'имеет',\n",
       " 'имеется',\n",
       " 'именно',\n",
       " 'иметь',\n",
       " 'имею',\n",
       " 'имеют',\n",
       " 'имеются',\n",
       " 'имеющегося',\n",
       " 'имеющее',\n",
       " 'имея',\n",
       " 'индивидуально',\n",
       " 'инобытии',\n",
       " 'интелегенцию',\n",
       " 'искажающей',\n",
       " 'исключает',\n",
       " 'исключающая',\n",
       " 'исключительно',\n",
       " 'истина',\n",
       " 'истине',\n",
       " 'истинно',\n",
       " 'истинного',\n",
       " 'истинное',\n",
       " 'истинной',\n",
       " 'истинную',\n",
       " 'истинные',\n",
       " 'истинным',\n",
       " 'истиной',\n",
       " 'истины',\n",
       " 'истолковал',\n",
       " 'исходит',\n",
       " 'исходят',\n",
       " 'исчезает',\n",
       " 'исчезла',\n",
       " 'их',\n",
       " 'к',\n",
       " 'каждая',\n",
       " 'каждого',\n",
       " 'каждое',\n",
       " 'каждый',\n",
       " 'кажется',\n",
       " 'казаться',\n",
       " 'как',\n",
       " 'какой',\n",
       " 'канта',\n",
       " 'кантовскую',\n",
       " 'касается',\n",
       " 'категории',\n",
       " 'категориям',\n",
       " 'качестве',\n",
       " 'качественное',\n",
       " 'ко',\n",
       " 'когда',\n",
       " 'конечного',\n",
       " 'конечности',\n",
       " 'конечность',\n",
       " 'конкретное',\n",
       " 'конкретной',\n",
       " 'конкретном',\n",
       " 'конкретный',\n",
       " 'конкретным',\n",
       " 'конкретных',\n",
       " 'коротко',\n",
       " 'которая',\n",
       " 'которого',\n",
       " 'которое',\n",
       " 'которой',\n",
       " 'котором',\n",
       " 'которому',\n",
       " 'которую',\n",
       " 'которые',\n",
       " 'который',\n",
       " 'которым',\n",
       " 'которых',\n",
       " 'крайности',\n",
       " 'краткой',\n",
       " 'кроме',\n",
       " 'кто',\n",
       " 'лежащее',\n",
       " 'лежит',\n",
       " 'ли',\n",
       " 'личности',\n",
       " 'личностью',\n",
       " 'лишь',\n",
       " 'логике',\n",
       " 'логическая',\n",
       " 'логические',\n",
       " 'логическое',\n",
       " 'ложная',\n",
       " 'любви',\n",
       " 'любом',\n",
       " 'людей',\n",
       " 'люди',\n",
       " 'максимы',\n",
       " 'мало',\n",
       " 'материал',\n",
       " 'материала',\n",
       " 'между',\n",
       " 'менее',\n",
       " 'меньшей',\n",
       " 'меня',\n",
       " 'мере',\n",
       " 'место',\n",
       " 'мир',\n",
       " 'мира',\n",
       " 'мире',\n",
       " 'миром',\n",
       " 'мне',\n",
       " 'мнимо',\n",
       " 'много',\n",
       " 'многообразие',\n",
       " 'многообразием',\n",
       " 'многообразное',\n",
       " 'многообразными',\n",
       " 'множественное',\n",
       " 'мной',\n",
       " 'могут',\n",
       " 'мое',\n",
       " 'моего',\n",
       " 'может',\n",
       " 'можно',\n",
       " 'моим',\n",
       " 'момент',\n",
       " 'момента',\n",
       " 'мощи',\n",
       " 'мощью',\n",
       " 'мы',\n",
       " 'мыслительного',\n",
       " 'мыслительных',\n",
       " 'мыслям',\n",
       " 'мыслящим',\n",
       " 'мышление',\n",
       " 'мышлением',\n",
       " 'мышлению',\n",
       " 'мышления',\n",
       " 'на',\n",
       " 'наблюдаемому',\n",
       " 'наблюдений',\n",
       " 'наблюдения',\n",
       " 'над',\n",
       " 'надобности',\n",
       " 'называет',\n",
       " 'называется',\n",
       " 'наказание',\n",
       " 'налицо',\n",
       " 'наличная',\n",
       " 'наличного',\n",
       " 'наличное',\n",
       " 'наличном',\n",
       " 'нам',\n",
       " 'нами',\n",
       " 'наоборот',\n",
       " 'наполнение',\n",
       " 'направление',\n",
       " 'направлено',\n",
       " 'например',\n",
       " 'напротив',\n",
       " 'народов',\n",
       " 'народы',\n",
       " 'наряду',\n",
       " 'нас',\n",
       " 'насилие',\n",
       " 'наук',\n",
       " 'находит',\n",
       " 'находится',\n",
       " 'находящаяся',\n",
       " 'начала',\n",
       " 'начало',\n",
       " 'начинает',\n",
       " 'нашего',\n",
       " 'нашем',\n",
       " 'не',\n",
       " 'не-\"я',\n",
       " 'не-я',\n",
       " 'неабсолютная',\n",
       " 'невероятным',\n",
       " 'него',\n",
       " 'недостаток',\n",
       " 'недостаточным',\n",
       " 'нее',\n",
       " 'независимого',\n",
       " 'независимости',\n",
       " 'незначительным',\n",
       " 'неистинное',\n",
       " 'ней',\n",
       " 'некоему',\n",
       " 'некоторого',\n",
       " 'некоторое',\n",
       " 'некоторому',\n",
       " 'некоторую',\n",
       " 'некоторый',\n",
       " 'некоторым',\n",
       " 'некоторыми',\n",
       " 'нем',\n",
       " 'нему',\n",
       " 'необходимо',\n",
       " 'необходимое',\n",
       " 'необходимому',\n",
       " 'необходимости',\n",
       " 'необходимость',\n",
       " 'необходимостью',\n",
       " 'необходимый',\n",
       " 'неопределенная',\n",
       " 'неопределенное',\n",
       " 'неподходящей',\n",
       " 'непосредственная',\n",
       " 'непосредственно',\n",
       " 'непосредственно-единичного',\n",
       " 'непосредственно-единичный',\n",
       " 'непосредственного',\n",
       " 'непосредственное',\n",
       " 'непосредственной',\n",
       " 'непосредственном',\n",
       " 'непосредственному',\n",
       " 'непосредственности',\n",
       " 'непосредственность',\n",
       " 'непосредственную',\n",
       " 'непосредственный',\n",
       " 'неразличное',\n",
       " 'неразрывно',\n",
       " 'несвободным',\n",
       " 'нет',\n",
       " 'нечто',\n",
       " 'нечувственное',\n",
       " 'ни',\n",
       " 'низводится',\n",
       " 'никакого',\n",
       " 'никакой',\n",
       " 'никогда',\n",
       " 'ним',\n",
       " 'ними',\n",
       " 'них',\n",
       " 'ничего',\n",
       " 'ничем',\n",
       " 'ничтожное',\n",
       " 'но',\n",
       " 'новое',\n",
       " 'нравственности',\n",
       " 'нуждающееся',\n",
       " 'о',\n",
       " 'об',\n",
       " 'оба',\n",
       " 'обе',\n",
       " 'обеих',\n",
       " 'обзора',\n",
       " 'обладает',\n",
       " 'обладаю',\n",
       " 'обладающее',\n",
       " 'обладающим',\n",
       " 'обладая',\n",
       " 'области',\n",
       " 'обнаружение',\n",
       " 'обнаружения',\n",
       " 'обнаруживающий',\n",
       " 'обнаруживающийся',\n",
       " 'обнаружился',\n",
       " 'обнаружить',\n",
       " 'обозначив',\n",
       " 'обоих',\n",
       " 'обоняния',\n",
       " 'обособлении',\n",
       " 'обособленное',\n",
       " 'обособляет',\n",
       " 'образом',\n",
       " 'образует',\n",
       " 'образующее',\n",
       " 'обратимся',\n",
       " 'обратно',\n",
       " 'обстоятельства',\n",
       " 'общего',\n",
       " 'общее',\n",
       " 'объединить',\n",
       " 'объект',\n",
       " 'объекта',\n",
       " 'объекте',\n",
       " 'объективная',\n",
       " 'объективного',\n",
       " 'объективное',\n",
       " 'объективной',\n",
       " 'объективном',\n",
       " 'объективности',\n",
       " 'объективность',\n",
       " 'объективностью',\n",
       " 'объективный',\n",
       " 'объектом',\n",
       " 'объекту',\n",
       " 'обыкновенного',\n",
       " 'овладеть',\n",
       " 'ограниченному',\n",
       " 'ограниченности',\n",
       " 'ограничивается',\n",
       " 'ограничивали',\n",
       " 'один',\n",
       " 'одна',\n",
       " 'однако',\n",
       " 'одновременно',\n",
       " 'одного',\n",
       " 'одной',\n",
       " 'одном',\n",
       " 'одностороннее',\n",
       " 'односторонней',\n",
       " 'односторонних',\n",
       " 'односторонность',\n",
       " 'означает',\n",
       " 'оказывается',\n",
       " 'оказываюсь',\n",
       " 'он',\n",
       " 'она',\n",
       " 'они',\n",
       " 'оно',\n",
       " 'опасности',\n",
       " 'опосредственному',\n",
       " 'опосредственный',\n",
       " 'опосредствования',\n",
       " 'опосредствованное',\n",
       " 'опосредствованный',\n",
       " 'опосредствующего',\n",
       " 'определен',\n",
       " 'определение',\n",
       " 'определении',\n",
       " 'определений',\n",
       " 'определения',\n",
       " 'определениями',\n",
       " 'определенно',\n",
       " 'определенного',\n",
       " 'определенное',\n",
       " 'определенности',\n",
       " 'определенность',\n",
       " 'определенную',\n",
       " 'определенным',\n",
       " 'определено',\n",
       " 'определены',\n",
       " 'определил',\n",
       " 'определяет',\n",
       " 'определяющий',\n",
       " 'опыт',\n",
       " 'опыте',\n",
       " 'опытом',\n",
       " 'освобождается',\n",
       " 'освобождающий',\n",
       " 'основание',\n",
       " 'основе',\n",
       " 'основу',\n",
       " 'особенности',\n",
       " 'особое',\n",
       " 'оставаясь',\n",
       " 'остается',\n",
       " 'останавливается',\n",
       " 'остающегося',\n",
       " 'осуществление',\n",
       " 'осуществляется',\n",
       " 'осуществляющееся',\n",
       " 'осязания',\n",
       " 'от',\n",
       " 'отделяет',\n",
       " 'отечеству',\n",
       " 'отказывается',\n",
       " 'открывает',\n",
       " 'открывается',\n",
       " 'откуда',\n",
       " 'отличаемо',\n",
       " 'отличается',\n",
       " 'отличающего',\n",
       " 'отлично',\n",
       " 'отличном',\n",
       " 'отличным',\n",
       " 'отмеченное',\n",
       " 'отнесен',\n",
       " 'отнесенное',\n",
       " 'отнесенность',\n",
       " 'отнесено',\n",
       " 'относительно',\n",
       " 'относится',\n",
       " 'относя',\n",
       " 'относясь',\n",
       " 'относящаяся',\n",
       " 'относящееся',\n",
       " 'отношение',\n",
       " 'отношении',\n",
       " 'отношений',\n",
       " 'отношению',\n",
       " 'отношения',\n",
       " 'отнюдь',\n",
       " 'отправную',\n",
       " 'отпускает',\n",
       " 'отрицает',\n",
       " 'отрицается',\n",
       " 'отрицание',\n",
       " 'отрицанием',\n",
       " 'отрицания',\n",
       " 'отрицательное',\n",
       " 'отрицательному',\n",
       " 'отрицательность',\n",
       " 'отсюда',\n",
       " 'отталкивания',\n",
       " 'отталкивая',\n",
       " 'отчуждение',\n",
       " 'отыскать',\n",
       " 'очевидным',\n",
       " 'очень',\n",
       " 'очередь',\n",
       " 'ощущений',\n",
       " 'ощущения',\n",
       " 'первая',\n",
       " 'первое',\n",
       " 'первоначально',\n",
       " 'первоначальное',\n",
       " 'первым',\n",
       " 'перед',\n",
       " 'перейти',\n",
       " 'переходит',\n",
       " 'по',\n",
       " 'поверхностная',\n",
       " 'повиновение',\n",
       " 'повиновению',\n",
       " 'погибает',\n",
       " 'погибнуть',\n",
       " 'подвергает',\n",
       " 'подлежащий',\n",
       " 'подлинно',\n",
       " 'подлинной',\n",
       " 'подлинном',\n",
       " 'поднявшиеся',\n",
       " 'поднято',\n",
       " 'поднять',\n",
       " 'подняться',\n",
       " 'подтверждении',\n",
       " 'подтверждения',\n",
       " 'подчинение',\n",
       " 'поединок',\n",
       " 'познаванием',\n",
       " 'познает',\n",
       " 'познается',\n",
       " 'познание',\n",
       " 'познанию',\n",
       " 'познано',\n",
       " 'познать',\n",
       " 'познающий',\n",
       " 'познающим',\n",
       " 'пока',\n",
       " 'показано',\n",
       " 'показывает',\n",
       " 'показывают',\n",
       " 'полагаемые',\n",
       " 'полагает',\n",
       " 'полагается',\n",
       " 'полагали',\n",
       " 'полагать',\n",
       " 'полагаю',\n",
       " 'полной',\n",
       " 'положена',\n",
       " 'положенное',\n",
       " 'положенный',\n",
       " 'положено',\n",
       " 'получает',\n",
       " 'получается',\n",
       " 'получил',\n",
       " 'помощи',\n",
       " 'понимает',\n",
       " 'понимается',\n",
       " 'понимать',\n",
       " 'поняла',\n",
       " 'понятие',\n",
       " 'понятии',\n",
       " 'понятию',\n",
       " 'понятия',\n",
       " 'понятиях',\n",
       " 'понято',\n",
       " 'понятый',\n",
       " 'попадает',\n",
       " 'пор',\n",
       " 'порождающее',\n",
       " 'порождению',\n",
       " 'порожденный',\n",
       " 'поскольку',\n",
       " 'после',\n",
       " 'последнего',\n",
       " 'последнее',\n",
       " 'последнем',\n",
       " 'последний',\n",
       " 'последним',\n",
       " 'последняя',\n",
       " 'последовательности',\n",
       " 'посредством',\n",
       " 'поставить',\n",
       " 'постигает',\n",
       " 'постигать',\n",
       " 'постигающее',\n",
       " 'постигнутое',\n",
       " 'постигнуть',\n",
       " 'постольку',\n",
       " 'постоянно',\n",
       " 'потом',\n",
       " 'потому',\n",
       " 'потребности',\n",
       " 'потустороннего',\n",
       " 'потустороннему',\n",
       " 'почему',\n",
       " 'почти',\n",
       " 'поэтому',\n",
       " 'права',\n",
       " 'правда',\n",
       " 'правильного',\n",
       " 'право',\n",
       " 'превращается',\n",
       " 'превращаются',\n",
       " 'превращен',\n",
       " 'превращением',\n",
       " 'превращения',\n",
       " 'предается',\n",
       " 'предела',\n",
       " 'пределами',\n",
       " 'пределах',\n",
       " 'пределы',\n",
       " 'предикатами',\n",
       " 'предмет',\n",
       " 'предмета',\n",
       " 'предметам',\n",
       " 'предметами',\n",
       " 'предмете',\n",
       " 'предметное',\n",
       " 'предметным',\n",
       " 'предметом',\n",
       " 'предмету',\n",
       " 'предположением',\n",
       " 'предположению',\n",
       " 'предположения',\n",
       " 'предположенное',\n",
       " 'предпосылка',\n",
       " 'предпосылками',\n",
       " 'предпосылкой',\n",
       " 'представление',\n",
       " 'представлении',\n",
       " 'представления',\n",
       " 'представляет',\n",
       " 'представляют',\n",
       " 'предчувствуется',\n",
       " 'предшествующая',\n",
       " 'предъявляет',\n",
       " 'прежде',\n",
       " 'претерпел',\n",
       " 'преходящее',\n",
       " 'при',\n",
       " 'прибавление',\n",
       " 'приводится',\n",
       " 'придается',\n",
       " 'признает',\n",
       " 'признается',\n",
       " 'признание',\n",
       " 'признания',\n",
       " 'признанного',\n",
       " 'признать',\n",
       " 'примечание',\n",
       " 'принадлежат',\n",
       " 'принадлежащего',\n",
       " 'принадлежащее',\n",
       " 'принадлежащие',\n",
       " 'принадлежащий',\n",
       " 'принадлежит',\n",
       " 'принимает',\n",
       " 'принцип',\n",
       " 'приобрести',\n",
       " 'приобретает',\n",
       " 'природа',\n",
       " 'природе',\n",
       " 'природная',\n",
       " 'природного',\n",
       " 'природное',\n",
       " 'природной',\n",
       " 'природности',\n",
       " 'природность',\n",
       " 'природную',\n",
       " 'природные',\n",
       " 'природный',\n",
       " 'природным',\n",
       " 'природу',\n",
       " 'природы',\n",
       " 'присущего',\n",
       " 'присущей',\n",
       " 'притом',\n",
       " 'приходит',\n",
       " 'приходится',\n",
       " 'пробудился',\n",
       " 'пробуждается',\n",
       " 'прогресс',\n",
       " 'прогрессирующее',\n",
       " 'продвигаться',\n",
       " 'продолжает',\n",
       " 'произволом',\n",
       " 'проистекающий',\n",
       " 'происходит',\n",
       " 'пройти',\n",
       " 'проникают',\n",
       " 'проникнутая',\n",
       " 'простая',\n",
       " 'просто',\n",
       " 'простого',\n",
       " 'простое',\n",
       " 'простом',\n",
       " 'пространстве',\n",
       " 'пространственная',\n",
       " 'противоположной',\n",
       " 'противоположности',\n",
       " 'противоположность',\n",
       " 'противоположным',\n",
       " 'противопоставило',\n",
       " 'противопоставить',\n",
       " 'противопоставляет',\n",
       " 'противопоставляется',\n",
       " 'противоречие',\n",
       " 'противоречием',\n",
       " 'противоречии',\n",
       " 'противоречия',\n",
       " 'противостоящее',\n",
       " 'процесс',\n",
       " 'процессе',\n",
       " 'прочное',\n",
       " 'проявление',\n",
       " 'проявляет',\n",
       " 'проявляется',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30\n",
    "sequences = []\n",
    "next_words = []\n",
    "for i in range(0, len(wl) - seq_length):\n",
    "    sequences.append(wl[i: i + seq_length])\n",
    "    next_words.append(wl[i + seq_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sequences are already tokenized and lowercased. Also 'eos' token is added to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_ix = vocab['eos']\n",
    "unk_ix = vocab['unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences), max_len), dtype='int32')\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [vocab.get(word, unk_ix) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[211]], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_matrix([[\"бытие\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 250,  540,  295,  381, 1143,  910,  955,    3,  686, 1496,  321,\n",
       "         407,    3,  360, 1360, 1122,   17,  787,   80,  758,  321,   13,\n",
       "          80, 1486,  399,  943,  413,    3,  360,  295],\n",
       "       [ 540,  295,  381, 1143,  910,  955,    3,  686, 1496,  321,  407,\n",
       "           3,  360, 1360, 1122,   17,  787,   80,  758,  321,   13,   80,\n",
       "        1486,  399,  943,  413,    3,  360,  295,  635],\n",
       "       [ 295,  381, 1143,  910,  955,    3,  686, 1496,  321,  407,    3,\n",
       "         360, 1360, 1122,   17,  787,   80,  758,  321,   13,   80, 1486,\n",
       "         399,  943,  413,    3,  360,  295,  635,   80]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "as_matrix(sequences[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will just build the language model (conditional probabilities distribution of words given some prefix sequence). To achieve this, I will just use plain LSTM RNN. To train it, I will use extracts from originl text of the length (say from 30 to 50) and use this model to predict next word given the sequence before. Actually, what I will do is just predicting probability of each word, so I will work with vocabulary (most popular 1500-2000 words) of constrained size. The loss function is cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the structure is partially borrowed from the exercises from https://github.com/yandexdataschool/Practical_DL/blob/master/homework04/part2_image_captioning.ipynb\n",
    "class CaptionNet(nn.Module):\n",
    "    def __init__(self, n_tokens=1501, emb_size=128, lstm_units=256, cnn_feature_size=2048):\n",
    "        \"\"\" A recurrent 'head' network for sequence generation. \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        # create embedding for input words. Use the parameters (e.g. emb_size).\n",
    "        self.emb = nn.Embedding(n_tokens, emb_size)\n",
    "            \n",
    "        self.lstm = nn.LSTM(emb_size, lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(lstm_units, n_tokens)\n",
    "        \n",
    "    def forward(self, captions_ix):\n",
    "        \"\"\" \n",
    "        Apply the network in training mode. \n",
    "        :param captions_ix: a Variable containing captions as matrix. shape: [batch, word_i]. \n",
    "            padded with pad_ix\n",
    "        :returns: logits for next token at each tick, shape: [batch, word_i, n_tokens]\n",
    "        \"\"\"\n",
    "        initial_cell = torch.zeros((captions_ix.size(0), 256)).unsqueeze(0).cuda()\n",
    "        initial_hid = torch.zeros((captions_ix.size(0), 256)).unsqueeze(0).cuda()\n",
    "\n",
    "        captions_emb = self.emb(captions_ix)\n",
    "        \n",
    "        batch_size, caption_len, emb_size = captions_emb.size()\n",
    "        caption_len = captions_emb.size()[1]\n",
    "        len_list = [caption_len for i in range(captions_emb.size()[0])]\n",
    "        input_seq = nn.utils.rnn.pack_padded_sequence(captions_emb, len_list, batch_first=True)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(input_seq, (initial_hid, initial_cell))\n",
    "        lstm_out = lstm_out.data.view(caption_len, batch_size, -1).permute(1, 0, 2)\n",
    "\n",
    "        logits = self.logits(lstm_out)\n",
    "        \n",
    "        return logits      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = 1501\n",
    "network = CaptionNet(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(network, captions_ix):   \n",
    "    # captions for input - all except last cuz we don't know next token for last one.\n",
    "    captions_ix_inp = captions_ix[:, :-1].contiguous()\n",
    "    captions_ix_next = captions_ix[:, 1:].contiguous()\n",
    "\n",
    "    # apply the network, get predictions for captions_ix_next\n",
    "    logits_for_next = network.forward(captions_ix_inp)\n",
    "    \n",
    "    batch_size, caption_len = captions_ix_next.size()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(logits_for_next.view(batch_size*caption_len, -1), captions_ix_next.view(batch_size*caption_len))\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaptionNet(\n",
       "  (emb): Embedding(1501, 128)\n",
       "  (lstm): LSTM(128, 256, batch_first=True)\n",
       "  (logits): Linear(in_features=256, out_features=1501, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating optimizer for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.cuda()\n",
    "opt = torch.optim.Adam(network.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting data into train and val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sequences = np.asarray(sequences)\n",
    "next_words = np.asarray(next_words)\n",
    "\n",
    "train_captions, val_captions, train_ans, val_ans = train_test_split(sequences, next_words,\n",
    "                                                                                test_size=0.1,\n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def generate_batch(captions, batch_size, max_caption_len=None):\n",
    "    \n",
    "    #sample random numbers for caption indicies\n",
    "    random_ix = np.random.randint(0, len(captions), size=batch_size)\n",
    "\n",
    "    captions_for_batch = captions[random_ix]\n",
    "    \n",
    "    #convert to matrix\n",
    "    batch_captions_ix = as_matrix(captions_for_batch,max_len=max_caption_len).astype(int)\n",
    "    \n",
    "    return Variable(torch.LongTensor(batch_captions_ix)).cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  883,   515,  1138,    13,  1175,  1448,  1385,  1371,    14,\n",
       "          1400,   611,  1135,     3,   432,   686,    71,    14,    80,\n",
       "           429,  1130,    13,  1126,    14,  1400,   611,     3,  1176,\n",
       "           422,   602,   947], device='cuda:0'),\n",
       " tensor([  350,    80,  1357,   328,   481,  1294,     3,    80,   423,\n",
       "          1299,  1368,  1153,   682,   360,  1269,   250,  1164,   658,\n",
       "            13,   923,    13,  1111,  1289,   352,  1164,   422,  1355,\n",
       "             3,   451,    80], device='cuda:0'),\n",
       " tensor([   14,   327,   255,  1372,     3,  1466,    14,    14,    80,\n",
       "            14,   319,  1029,   700,     3,  1370,   326,   372,   676,\n",
       "           372,  1483,   700,    14,    14,   323,    14,     3,  1370,\n",
       "          1484,   319,   726], device='cuda:0')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(generate_batch(sequences,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop\n",
    "\n",
    "Train on minibatches just as usual. Evaluate on val from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = len(train_captions)\n",
    "N_val= len(val_captions)\n",
    "batch_size = 128  # adjust me\n",
    "n_epochs = 100  # adjust me\n",
    "n_batches_per_epoch = N_train//batch_size  # adjust me\n",
    "n_validation_batches = N_val//batch_size   # how many batches are used for validation after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8f40342d6545378dfe0940f617e479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 0, train loss: 5.575155717780791, val loss: 4.9975600772433815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf63e36dd07043a09d3ec7fde5dacdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 1, train loss: 4.598073160791972, val loss: 4.28401353624132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228eabb7d7b948328921f4276236ee81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 2, train loss: 3.9150280981178742, val loss: 3.628547774420844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b150f2c259e4c90adf3f691832bba5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 3, train loss: 3.319160263222384, val loss: 3.0937283039093018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a714db4db64bbb9a0b0a81bdd78f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 4, train loss: 2.7975434940981576, val loss: 2.6195134851667614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663050c994e44ed8867c08e2d8c292ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 5, train loss: 2.3633670490908334, val loss: 2.245490868886312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c52a2e2755c4a489a9a34a88c84a5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 6, train loss: 2.005252325391195, val loss: 1.9187861283620198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11405b6c4072446bad41a2f04eed6a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 7, train loss: 1.7058123436318822, val loss: 1.6529371076160007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f488c1d38fe43b090cc9892219586d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 8, train loss: 1.4467661021703697, val loss: 1.392942984898885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e86f2895cc48f79b31274f54a58473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 9, train loss: 1.2318476395434643, val loss: 1.2035102446873982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a562da965a14ce2a44d09a6a0d830ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 10, train loss: 1.0439868748906147, val loss: 1.0377031962076824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb598642b6ba4a3f9b08cdd2dda3bfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 11, train loss: 0.8854383230209351, val loss: 0.8841807378662957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a46856fdb564f55a6f07e5fd752816b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 12, train loss: 0.7578568314931479, val loss: 0.7835063205824958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716ce605b0f44a45ad097ab807c2b85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 13, train loss: 0.6573388131268053, val loss: 0.6750806437598335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cfc34fafec45048e6a0db9c9746cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 14, train loss: 0.5713456028915314, val loss: 0.6072143250041537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1163433f9364cd0bd4eae3934d7dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 15, train loss: 0.5041206353400127, val loss: 0.5392769045299954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cceee9e11654ac38bb7f087dc8368cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 16, train loss: 0.4498921841023916, val loss: 0.49171894126468235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee382c9b21f400faf42ac433e25e14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 17, train loss: 0.40321885534079677, val loss: 0.45615735318925643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377d4776c1fb4be5b20c9c1183f0bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 18, train loss: 0.3641209236110549, val loss: 0.42626358403099907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5d1228d1c14d768bbfbbdda32162cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 19, train loss: 0.338126566036638, val loss: 0.3982640736632877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42954b2c996f475581583fc87785b965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 20, train loss: 0.3133104303515101, val loss: 0.37729722261428833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79a94d10eba43f3b88b4ce781387c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 21, train loss: 0.29159904495779293, val loss: 0.36072802874777055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240c9f2a3dd44c4d8595c7ac90c47bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 22, train loss: 0.27454146383756617, val loss: 0.3497927188873291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b10df693f343cf8744dec6c47e84c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 23, train loss: 0.2607094473149403, val loss: 0.340895887878206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d82f49658424979893f1745f8fba093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 24, train loss: 0.247806845659233, val loss: 0.3235565192169613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6c866cd4c749b69cac186d04cb2445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 25, train loss: 0.23881145611584906, val loss: 0.3158655928240882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7b5a3d53174918a8628ac4fdce143f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 26, train loss: 0.22680078249379812, val loss: 0.31391803092426723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa95c261154e81bdc2ff478c468ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 27, train loss: 0.22067251226988183, val loss: 0.30342626240518356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f3c3726ce047d98994a27860d5c012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 28, train loss: 0.2124744079199182, val loss: 0.29177021318011814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85191efdf9504684ac3351b45a3ba973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 29, train loss: 0.2072596122701484, val loss: 0.29502227240138584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b65d7fc8dba46f98900aff4eefdf4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 30, train loss: 0.2026153366608792, val loss: 0.29182083076900905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4298c7f46e4437835c1e886d652f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1789f6541670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_train = len(train_captions)\n",
    "N_val= len(val_captions)\n",
    "batch_size = 128  # adjust me\n",
    "n_epochs = 100  # adjust me\n",
    "n_batches_per_epoch = N_train//batch_size  # adjust me\n",
    "n_validation_batches = N_val//batch_size   # how many batches are used for validation after each epoch\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss=0\n",
    "    network.train(True)\n",
    "    for _ in tqdm_notebook(range(n_batches_per_epoch)):\n",
    "        # clear old gradients; do a backward pass to get new gradients; then train with opt        \n",
    "        opt.zero_grad()\n",
    "        loss_t = compute_loss(network, generate_batch(train_captions, batch_size))\n",
    "\n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "        train_loss += loss_t.data.cpu().numpy().flatten()[0]\n",
    "        \n",
    "    train_loss /= n_batches_per_epoch\n",
    "    \n",
    "    val_loss=0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t = compute_loss(network, generate_batch(val_captions, batch_size))\n",
    "        val_loss += loss_t.data.cpu().numpy().flatten()[0]\n",
    "    val_loss /= n_validation_batches\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss, val_loss))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have just tried several times and make estimation while stopping the training and could say that 20 epochs is more than enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(caption_prefix = (\"а\",), \n",
    "                     t=1, sample=True, max_len=100):\n",
    "    \n",
    "    caption_prefix = list(caption_prefix)\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        \n",
    "        prefix_ix = as_matrix([caption_prefix])\n",
    "        prefix_ix = Variable(torch.LongTensor(prefix_ix.astype(int)), volatile=True).cuda()\n",
    "        next_word_logits = network.forward(prefix_ix)[0, -1]\n",
    "        next_word_probs = F.softmax(next_word_logits).data.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        assert len(next_word_probs.shape) ==1, 'probs must be one-dimensional'\n",
    "        next_word_probs = next_word_probs ** t / np.sum(next_word_probs ** t) # apply temperature\n",
    "\n",
    "        if sample:\n",
    "            next_word = np.random.choice(vocabulary_inv, p=next_word_probs) \n",
    "        else:\n",
    "            next_word = vocabulary_inv[np.argmax(next_word_probs)]\n",
    "\n",
    "        caption_prefix.append(next_word)\n",
    "\n",
    "        if next_word==\"eos\":\n",
    "            break\n",
    "            \n",
    "    return caption_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['а',\n",
       " 'также',\n",
       " 'благодаря',\n",
       " 'тому',\n",
       " ',',\n",
       " 'что',\n",
       " 'unknown',\n",
       " 'есть',\n",
       " 'в',\n",
       " 'себе',\n",
       " 'и',\n",
       " 'для',\n",
       " 'самосознания',\n",
       " 'по',\n",
       " 'отношению',\n",
       " 'ко',\n",
       " 'мне',\n",
       " 'быть',\n",
       " 'некоторым',\n",
       " 'самостоятельным',\n",
       " 'другим',\n",
       " ',',\n",
       " 'чем-то',\n",
       " 'рефлектированным',\n",
       " 'в',\n",
       " 'самое',\n",
       " 'себя',\n",
       " ',',\n",
       " 'как',\n",
       " 'другое',\n",
       " 'для',\n",
       " 'другого',\n",
       " 'только',\n",
       " 'как',\n",
       " 'сущее',\n",
       " ',',\n",
       " 'и',\n",
       " 'другое',\n",
       " 'eos']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_caption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['а',\n",
       " 'абсолютная',\n",
       " 'деятельность',\n",
       " ';',\n",
       " 'и',\n",
       " 'оно',\n",
       " 'действительно',\n",
       " 'снимает',\n",
       " 'его',\n",
       " ',',\n",
       " 'поскольку',\n",
       " 'unknown',\n",
       " 'предметом',\n",
       " ',',\n",
       " 'только',\n",
       " 'unknown',\n",
       " 'себя',\n",
       " 'за',\n",
       " 'самостоятельный',\n",
       " ',',\n",
       " '-',\n",
       " 'unknown',\n",
       " 'себя',\n",
       " ',',\n",
       " 'unknown',\n",
       " 'его',\n",
       " ',',\n",
       " 'и',\n",
       " 'сохраняет',\n",
       " 'себя',\n",
       " 'в',\n",
       " 'этом',\n",
       " 'процессе',\n",
       " ',',\n",
       " 'так',\n",
       " 'как',\n",
       " 'оно',\n",
       " '-',\n",
       " 'самоцель',\n",
       " 'eos']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_caption(t=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_xx = spacy.load('xx_ent_wiki_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordlist(doc):\n",
    "    wl = []\n",
    "    for word in doc:\n",
    "        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "            wl.append(word.text.lower())\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_wl(filename):\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    data = data.replace('\\n', ' ').replace('a', 'а').strip()\n",
    "    sents = data.split('.') #this is quite silly tokenizationm but spacy could not provide accurate enough tokenization for Russian, though\n",
    "    data = \" EOS \".join(sents) #[\"START \" + s for s in sents]\n",
    "    data = re.sub(' +',' ', data) # just to handle this naughty spaces\n",
    "    doc = spacy_xx(data)\n",
    "    wl = create_wordlist(doc)\n",
    "    \n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "N_most_common = 2000\n",
    "\n",
    "txt_paths = ['revisor.txt', 'fenomen.txt']\n",
    "texts_wl = []\n",
    "voc_set = set()\n",
    "\n",
    "for filename in txt_paths:\n",
    "    wl = create_wl(filename)\n",
    "    texts_wl.append(wl)\n",
    "    word_counts = collections.Counter(wl)\n",
    "    wc_most_common = word_counts.most_common(n=N_most_common)\n",
    "    voc_set |= set([x[0] for x in wc_most_common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  3669\n"
     ]
    }
   ],
   "source": [
    "# Mapping from index to word : that's the vocabulary\n",
    "words = list(voc_set)\n",
    "vocabulary_inv = [\"unknown\"] + words\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "\n",
    "#size of the vocabulary\n",
    "vocab_size = len(words)\n",
    "print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50\n",
    "sequences = []\n",
    "for wl in texts_wl:\n",
    "    for i in range(0, len(wl) - seq_length):\n",
    "        sequences.append(wl[i: i + seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = vocab_size + 1\n",
    "network = CaptionNet(n_tokens)\n",
    "network.cuda()\n",
    "opt = torch.optim.Adam(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sequences = np.asarray(sequences)\n",
    "\n",
    "train_captions, val_captions = train_test_split(sequences, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['сознания', 'и', 'самосознания', 'содержит', 'в', 'себе', 'прежде',\n",
       "       'всего', 'единичные', 'личности', 'как', 'светящиеся',\n",
       "       'видимостью', 'друг', 'в', 'друге', 'eos', 'но', 'их', 'различие',\n",
       "       'в', 'этом', 'тождестве', 'есть', 'совершенно', 'неопределенная',\n",
       "       'разность', 'их', 'или', ',', 'скорее', ',', 'такое', 'различие',\n",
       "       ',', 'которое', 'не', 'есть', 'различие', 'eos', 'их', 'истина',\n",
       "       'есть', 'поэтому', 'в-себе-и-для-себя', 'сущая', 'всеобщность',\n",
       "       'и', 'объективность', 'самосознания'], dtype='<U29')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b7cf2e326f47f9a8f6732e7127f343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 0, train loss: 5.1377797376859435, val loss: 4.337369272785802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacdced759d148fc96bebe253f1a2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 1, train loss: 3.8412239709934153, val loss: 3.4446707002578245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0337b42c2c23449591a2ef12991a3a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 2, train loss: 3.105330874036242, val loss: 2.8535905422702914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4bde3a0b7e4fc8bd64c03a09d0430f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 3, train loss: 2.5899738690236234, val loss: 2.4074318255147626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ea7c163c7344a596d18353e6a041cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 4, train loss: 2.1838743644994456, val loss: 2.0437165844825005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ae2070e8d840de85397a6354f515ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 5, train loss: 1.8430378036899167, val loss: 1.7157285674925773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfd850ed99b40be81271978c37f6d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 6, train loss: 1.54700153274136, val loss: 1.4511906062403033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8811607c5b8e41b7a121d9a84046472b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 7, train loss: 1.3049590145791328, val loss: 1.2235510387728292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cda41248eb44724b903c551f9007b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 8, train loss: 1.0972145118496635, val loss: 1.042678456152639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1115468a46da4607955fe56d9910e0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 9, train loss: 0.9210569064517121, val loss: 0.8745724039693032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fad021509f4da39f2a8e6f4444490a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 10, train loss: 0.7652992979213075, val loss: 0.7324948003215175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d698081be94479b095bb9f950b55ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 11, train loss: 0.6336869311916244, val loss: 0.6110076269795818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaca47f7e5824240aa8456cd5db6b58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 12, train loss: 0.5236102739622542, val loss: 0.517160314706064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c1fc61be0d42818e4225b0fbe275fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 13, train loss: 0.43589149676002825, val loss: 0.4356150079158045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da0a9a9e3114f0b9f9447e3c6af32ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=286), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 14, train loss: 0.36631983299772225, val loss: 0.38079540864113837\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "N_train = len(train_captions)\n",
    "N_val= len(val_captions)\n",
    "batch_size = 128  # adjust me\n",
    "n_epochs = 15  # adjust me\n",
    "n_batches_per_epoch = N_train//batch_size  # adjust me\n",
    "n_validation_batches = N_val//batch_size   # how many batches are used for validation after each epoch\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss=0\n",
    "    network.train(True)\n",
    "    for _ in tqdm_notebook(range(n_batches_per_epoch)):\n",
    "        # clear old gradients; do a backward pass to get new gradients; then train with opt        \n",
    "        opt.zero_grad()\n",
    "        loss_t = compute_loss(network, generate_batch(train_captions, batch_size))\n",
    "\n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "        train_loss += loss_t.data.cpu().numpy().flatten()[0]\n",
    "        \n",
    "    train_loss /= n_batches_per_epoch\n",
    "    \n",
    "    val_loss=0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t = compute_loss(network, generate_batch(val_captions, batch_size))\n",
    "        val_loss += loss_t.data.cpu().numpy().flatten()[0]\n",
    "    val_loss /= n_validation_batches\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss, val_loss))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eos упомянутое рабское самосознание , все одушевленное и дух обнаружился в тождестве с самим собой и является разум внешний объект для других , предмет тождество , внешний совершенно справедливо для противоречия характер ; другое что для себя теперь является не \" я \" , погружается во внутреннее самости , государства , через снятие их таким unknown ; единичности , до бы только , то , чему из unknown ехать по весьма unknown делу ну unknown тогда unknown для себя \" я определил как вам eos'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(generate_caption([\"eos\", ], t = .7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'вам счастье прежде всего сути , просто и к идее природы что-нибудь завтраком eos'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(generate_caption([\"вам\", ], t = .7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'друг , как его жена и \" я \" , постольку самосознание есть в то же время у себя как углубление , проникновение и внедрение в особенно который тождество - в его абсолютной истине не только с объектом , вот другое , а не unknown со мной на дружеской ноге eos'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(generate_caption([\"друг\", ], t = .7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, the reslts are quite interesting, but nevertheless not ideal, since this particular approach is just sampling from the general language model which describes two texts. But of course, if in general texts are of different style and even have very little words in common, then several initial words will define almost surely the rest part of sequence and also the whole style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now what?\n",
    "\n",
    "This model produces some texts but one might still strive to improve it. To this end, I will leave here some ideas. \n",
    "One approach will be based on the classificator: so, zero-step is to build a classfier which given a sequence will output whether it from Gogol or Hegel. Speaking of neural network architecture, I will try basic LSTM with softmax layer. Then I will find such input which minimizes squared difference between probabilities of authorship. This could be done using gradient descent, since we already know weights of the neural network.\n",
    "\n",
    "In this basic version, I have replaced all rare words with 'unkown' which throws away a lot of information and reduces quality. I will try looking at https://arxiv.org/abs/1508.07909\n",
    "\n",
    "Moreover, it seems to be right task to check whether 'attention is' really 'what we need'...\n",
    "Just to start with https://arxiv.org/abs/1502.03044 and 'Attention Is All You Need' https://arxiv.org/pdf/1706.03762\n",
    "Then getting the words with highest attention corresponding to each author, one might just randomly force during sampling either word corresponding to Gogol or Hegel. Then text in the result should look as mix of both styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
